set(TARGET llama-rrs-benchmark)

if (GGML_CUDA)
    enable_language(CUDA)
    add_executable(${TARGET} main.cu)
    target_link_libraries(${TARGET} PRIVATE ggml)
    install(TARGETS ${TARGET} RUNTIME)
else()
    message(STATUS "RRS benchmark skipped (requires GGML_CUDA=ON)")
endif()
